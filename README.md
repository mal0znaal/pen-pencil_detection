# Тестовое задание "Детекция карандашей и ручек"

Цель: обучить и сравнить несколько моделей YOLO для детекции двух классов — **ручка** (`pen`) и **карандаш** (`pencil`) — на своих данных, а затем проверить качество на отдельном тестовом видео (и в реальном времени).

---

## 1. Постановка задачи

Техническое задание:

- Записать **два видео по ~30 секунд** с ручками и карандашами на столе:
  - первое видео — для формирования обучающего датасета;
  - второе — для финальной проверки модели.
- Выбрать **60 кадров** из первого видео:
  - 50 изображений в `train`;
  - 10 изображений в `val`.
- Разметить изображения:
- Обучить несколько моделей YOLO на GPU.
- Оценить метрики и ответить:
  - какая модель лучше;
  - как она ведёт себя на втором видео;
  - попробовать запустить модель в real-time.

---

## 2. Данные

### 2.1 Сбор

Было записано два видео:

- **video_train.mp4** — ~30 секунд, 3 ручки и 2 карандаша на столе, разные ракурсы и движения камеры. На некоторых кадрах предметы частично (или полностью) пропадают из зоны выдимости
- **video_test.mp4** — второе видео в отличающихся условиях:
  - немного другое расположение предметов;
  - частично другие фоны/углы.

### 2.2 Разметка

Разметка выполнялась в сервисе **Roboflow**, для ускорения этого этапа применялась модель **SAM3** для автоматической разметки. После работы **SAM3** каждое изображение проверялось и корректировалось вручную. Ссылка на датасет: https://app.roboflow.com/testproject-64hot/pen_penicl1-4izcj/1

Разделение на выборки:
- **train** — 50 изображений;
- **val** — 10 изображений.

---

## 3. Обучение модели

### 3.1 Первый эксперимент

После получение готового набора данных, была обучена модель **YOLO12s** на 50 эпохах. Все гиперпараметры обучения стандартные, кроме:  
- **Batch_size** выбирался автоматически, чтобы занимать **75%** VRAM
- **imgsz** = 640. Изображения сжимались до 640 пикселей по ширине с сохранением пропорций.

Цель - получить базовую модель без специального тюнинга и аугментаций а после понять, как предобученная YOLO12s справляется с задачей на данном датасете. 

| Class  | Precision (P) | Recall (R) | mAP@0.5 | mAP@0.5:0.95 |   F1   |
|--------|---------------|------------|---------|--------------|--------|
| all    | 0.996         | 0.985      | 0.995   | 0.869        | 0.9908 |
| pen    | 1.000         | 0.971      | 0.995   | 0.903        | ------ |
| pencil | 0.993         | 1.000      | 0.995   | 0.835        | ------ |

Результаты на вылидационной выборке оказались хорошими, однако для точной оценки результата стоит проверить как модель покажет себя в боевых условиях (второе видео, записанное для тестирования).  
И с этим возникают проблемы: Модель хорошо выделяет `bound boxes`, но ошибается в классификации. Один определенный карандаш ошибочно определяется за ручку.

#### Демонстрация работы модели до аугментаций



<div align="center">  


https://github.com/user-attachments/assets/d4ab74ed-2bb3-4b00-9717-99f59a80c7bb


</div>

<p align="center">
  <em>Видео: 16 секунд, ~6&nbsp;МБ</em>
</p>

#### Гипотеза 1: конкуренция классов по уверенности (conf / NMS)

Посмотрим в чем проблема, если посмотреть видео подробно - то видно, что в какой-то момент модель все же верно классифицирует объект (к регрессионной способности определять ограничивающие рамки вопросов не возникает).  
Возможно, **conf** для классификации как `ручка` чуть выше чем для `карандаш`, и после срабатывания NMS мы не видим результат.  
Для проверки гипотезы очень сильно понизим порог NMS, в надежде увидить в той же области `bound box`, классифицированный как `карандаш`

![neg_case2](https://github.com/user-attachments/assets/5b998333-cc88-4240-86e0-d7e67a8e3cc1)

Результат: 
- модель **вообще не генерирует** детекций класса `карандаш` на этом объекте.
- проблема не в NMS и похожих уровнях **conf**, а в том, что модель **не воспринимает этот объект как карандаш в принципе**.

#### Гипотеза 2: Проблема с углами обзора
Но так как модель отлично определяет рамки -> делаем вывод, что модель еще не научилась различать ручки и карандаши.  
Это сильно зависит от **ориентации** и  **ракурса** съемки. 

Чтобы проверить эту гипотезу - повернем прошлое фото на 90°:
![neg_case](https://github.com/user-attachments/assets/cb3a1d0e-59da-4c13-b045-178f1a6dfaba)
И вау, модель распознала карандаш как `карандаш`, но ошиблась с ручкой)).

Результат: 
- модель сильно чувствительна к ориентации и ракурсу и переобучилась на ограниченном наборе из обучающей выборки.

### 3.2 Обучение новой модели с осознанием проблемы

Решим возникшую проблему 2 способами:
1. Добавим в обучающую выборку еще **10** изображений `проблемного` карандаша с различных ракурсов. Новый датасет: https://app.roboflow.com/testproject-64hot/pen_penicl1-4izcj/3
2. Применим дополнительные аугментации и обучим модель снова, на **дополненном** датасете:

```
    degrees=30.0,   # поворот ±30°
    scale=0.5,      # изменение масштаба
    shear=10.0,     # имитация съемки с разных углов
    fliplr=0.5,     # горизонтальные отражения
```

| Class  | Precision (P) | Recall (R) | mAP@0.5 | mAP@0.5:0.95 |   F1   |
|--------|---------------|------------|---------|--------------|--------|
| all    | 0.900         | 0.889      | 0.993   | 0.93         | 0.8946 |
| pen    | 0.980         | 1.000      | 0.995   | 0.995        | ------ |
| pencil | 0.820         | 0.778      | 0.865   | 0.865        | ------ |

Результаты на валидационном наборе стали чуть хуже, но что же с работой модели в реальных (тестовых) условиях? Из видео ниже заметно, что результат стал гораздо **лучше**. Классифицирующая способность модели стала только лучше.  
В целом, можно сказать, что модель стала **устойчивее**.

#### Демонстрация работы модели после аугментаций



<div align="center">  




https://github.com/user-attachments/assets/b3097126-eabd-4963-95e1-493ddac986a5




</div>

<p align="center">
  <em>Видео: 16 секунд, ~6&nbsp;МБ</em>
</p>
